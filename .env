# Provider Configuration (NEW!)
LLM_PROVIDER=openai
LLM_MODEL=gpt-5.2-codex
LLM_API_KEY=sk-api-key
# LLM_BASE_URL=http://localhost:1234/v1  # Для локальных моделей

# Reasoning effort для reasoning моделей (low/medium/high)
# Используется только для o1/o3 моделей и codex с reasoning
LLM_REASONING_EFFORT=medium

EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_API_KEY=sk-api-key
# EMBEDDING_BASE_URL=http://localhost:1234/v1

PROVIDER_MAX_RETRIES=3
PROVIDER_TIMEOUT=60

# Legacy OpenAI Configuration (для обратной совместимости)
OPENAI_API_KEY=sk-api-key
OPENAI_MODEL=gpt-5.2-codex
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_MAX_RETRIES=3
OPENAI_TIMEOUT=60

# ChromaDB Configuration
CHROMA_PERSIST_DIRECTORY=/path/to/folder

# Indexing Configuration
MAX_FILE_SIZE_MB=1
MAX_CHUNK_SIZE_TOKENS=6000
CHUNK_OVERLAP_TOKENS=500
MAX_CONCURRENT_FILES=5
RATE_LIMIT_RPM=3500
RATE_LIMIT_TPM=1000000

# Server Configuration
LOG_LEVEL=INFO
SERVER_NAME=project-indexer
SERVER_VERSION=1.0.0

# Web Server Configuration (Admin Portal)
WEB_HOST=0.0.0.0
WEB_PORT=8080
WEB_ENABLE=false
